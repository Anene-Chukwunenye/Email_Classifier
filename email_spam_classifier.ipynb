{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce811bf",
   "metadata": {},
   "source": [
    "# A classifier model to accurately classify if an email is 'spam' or 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e6388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f994664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('SMSSpamCollection',sep='\\t',names=['label','text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f121dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad1b0d2",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c0f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to clean text using the 're'library\n",
    "\n",
    "def text_cleanup(text):\n",
    "    text=text.lower()\n",
    "    #removes numbers\n",
    "    text = re.sub(r\"\\b\\d+\\b\",\"\",text)\n",
    "    #replacing some common English contraction:\n",
    "    text = re.sub(r\"what's\",\"what is\",text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"\\'don't\", \" do not \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b56d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']= data['text'].apply(lambda x: text_cleanup(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04dbaa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i do not  think he goes to usf, he lives a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  go until jurong point, crazy.. available only ...\n",
       "1   ham                      ok lar... joking wif u oni...\n",
       "2  spam  free entry in  a wkly comp to win fa cup final...\n",
       "3   ham  u dun say so early hor... u c already then say...\n",
       "4   ham  nah i do not  think he goes to usf, he lives a..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bc4e1",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "749e733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punctuation= [words for words in text if words not in string.punctuation]\n",
    "    text_no_punct= ''.join(no_punctuation)\n",
    "    return text_no_punct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0ed690",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']= data['text'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d420c834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i do not  think he goes to usf he lives ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry in  a wkly comp to win fa cup final...\n",
       "3   ham        u dun say so early hor u c already then say\n",
       "4   ham  nah i do not  think he goes to usf he lives ar..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dcb055",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "108bcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the sentences into individual words\n",
    "\n",
    "def tokenization(text):\n",
    "    split= re.split(\"\\W+\",text)\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae62714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1db133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, do, not, think, he, goes, to, usf, he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  [go, until, jurong, point, crazy, available, o...\n",
       "1   ham                     [ok, lar, joking, wif, u, oni]\n",
       "2  spam  [free, entry, in, a, wkly, comp, to, win, fa, ...\n",
       "3   ham  [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4   ham  [nah, i, do, not, think, he, goes, to, usf, he..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87c033",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e1dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52f35aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c310324",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1db65d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [go, jurong, point, crazy, available, bugis, n...\n",
       "1                       [ok, lar, joking, wif, u, oni]\n",
       "2    [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3        [u, dun, say, early, hor, u, c, already, say]\n",
       "4       [nah, think, goes, usf, lives, around, though]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa602f3",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "530e3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b49a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatized_text= ' '.join([lemmatizer.lemmatize(w) for w in text ])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad59fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414839b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazy available bugis n great ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry wkly comp win fa cup final tkts 21s...\n",
       "3                  u dun say early hor u c already say\n",
       "4                  nah think go usf life around though\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a8c466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted the target variable into binary form using label encoder\n",
    "le= preprocessing.LabelEncoder()\n",
    "data['label']=le.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feda24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['text']\n",
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ae1ccbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195fd5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ed6341e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51236e5d",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53854122",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= TfidfVectorizer(lowercase=False)\n",
    "x= vectorizer.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaea00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "289fa8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=.2,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ecb9b",
   "metadata": {},
   "source": [
    "# Naive_Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8d27756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a74b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(x_train, y_train)\n",
    "y_pred=spam_detect_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a07ae862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "402a5740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the spam_detector_model(Naive_Bayes): 0.9614349775784753 \n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the spam_detector_model(Naive_Bayes): {} '.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8117a9",
   "metadata": {},
   "source": [
    "# LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c74e633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7546f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model_LR= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d1e647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model_LR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63b0eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LR=spam_detect_model_LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "438d1734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the spam_detector_model(LogisticRregression): 0.9533632286995516 \n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the spam_detector_model(LogisticRregression): {} '.format(accuracy_score(y_test,y_pred_LR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efcf355",
   "metadata": {},
   "source": [
    "From my observation, the Naive_Bayes Model performed better than the LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab6997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
